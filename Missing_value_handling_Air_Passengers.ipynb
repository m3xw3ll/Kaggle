{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1913,"sourceType":"datasetVersion","datasetId":1057}],"dockerImageVersionId":30474,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mexwell/missing-value-handling-air-passengers?scriptVersionId=130100383\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<center>\n    <img widht='300px' src='https://cdn-icons-png.flaticon.com/512/38/38785.png?w=1800&t=st=1684435095~exp=1684435695~hmac=d7b2b610f4938144ad0bf0fddb2af07d7d4c5af0ef57d7d70eab3efe6515c3a5'>\n    \n# Missing value handling - Air Passengers - LightGBM Regression\n</center>\n\nMissing value handling for time series forecasting is crucial for several reasons:\n\n- **Accurate forecasting:** Time series data often exhibits patterns and dependencies over time. Missing values disrupt this continuity and can lead to inaccurate forecasts if not properly handled. By addressing missing values, we can ensure that the underlying patterns and relationships in the data are preserved, leading to more accurate predictions.\n- **Data completeness:** Missing values can result from various factors, such as data collection errors, sensor failures, or system downtime. Ignoring or improperly handling these missing values can introduce bias and distort the overall data representation. Handling missing values allows us to maintain data completeness and avoid potential biases in the forecasting process.\n- **Consistency in time-dependent relationships:** Time series data often involves relationships between variables at different time points. Missing values can break these relationships, making it challenging to capture the dynamics and dependencies accurately. Handling missing values appropriately helps maintain the consistency of these time-dependent relationships and enables accurate modeling of the underlying patterns.\n- **Statistical modeling requirements:** Many time series forecasting models, such as autoregressive integrated moving average (ARIMA) or seasonal decomposition of time series (STL), have assumptions about the data, such as stationarity or independence. Missing values can violate these assumptions and lead to biased or unreliable model outputs. Proper handling of missing values ensures that the data adheres to the model requirements, leading to more robust and reliable forecasts.\n- **Utilizing all available information:** Time series data often contains valuable information that can aid in forecasting. By effectively handling missing values, we can make the best use of the available information and avoid discarding potentially useful data points. This improves the overall predictive power of the forecasting models and allows for more accurate predictions.\n\n\nIn summary, missing value handling in time series forecasting is important to preserve data integrity, maintain time-dependent relationships, meet statistical modeling assumptions, and leverage the full potential of the available information. It ultimately contributes to more accurate and reliable forecasts.\n\nIn this notebook I will show some easy techniques for handling missing values. At the end I will train a LightGBM model to predict the number of passengers per month. ","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"## About the Dataset\n\nThe dataset contains number of air passengers of each month from the year 1949 to 1960. ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_error\n\nsns.set(style=\"whitegrid\", color_codes=True, font_scale=1.3)\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:02:34.278004Z","iopub.execute_input":"2023-05-18T19:02:34.278403Z","iopub.status.idle":"2023-05-18T19:02:36.165969Z","shell.execute_reply.started":"2023-05-18T19:02:34.278372Z","shell.execute_reply":"2023-05-18T19:02:36.165073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First let´s load the dataset and get a general overview. ","metadata":{}},{"cell_type":"code","source":"original = pd.read_csv('/kaggle/input/air-passengers/AirPassengers.csv', index_col=['Month'], parse_dates=['Month'])\noriginal = original.rename(columns={'#Passengers': 'Passengers'})","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:02:45.444805Z","iopub.execute_input":"2023-05-18T19:02:45.445154Z","iopub.status.idle":"2023-05-18T19:02:45.476667Z","shell.execute_reply.started":"2023-05-18T19:02:45.445127Z","shell.execute_reply":"2023-05-18T19:02:45.475993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:02:47.732298Z","iopub.execute_input":"2023-05-18T19:02:47.732627Z","iopub.status.idle":"2023-05-18T19:02:47.758293Z","shell.execute_reply.started":"2023-05-18T19:02:47.732602Z","shell.execute_reply":"2023-05-18T19:02:47.756917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original.describe()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:03:53.314871Z","iopub.execute_input":"2023-05-18T19:03:53.315233Z","iopub.status.idle":"2023-05-18T19:03:53.33325Z","shell.execute_reply.started":"2023-05-18T19:03:53.315204Z","shell.execute_reply":"2023-05-18T19:03:53.331871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset isn´t too complex. We have 2 columns, one for the `month` and the other column is our target. \n\nIn total we have 144 rows. Not very much, but let´s see if we can do something with it. \n\nAs desribed above missing values are crucial for our prediction. Let´s see if we have any missing values. ","metadata":{}},{"cell_type":"code","source":"no_missing_vals = original['Passengers'].isnull().sum()\nprint(f'No of missing observations: {no_missing_vals}')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:03:55.762462Z","iopub.execute_input":"2023-05-18T19:03:55.762916Z","iopub.status.idle":"2023-05-18T19:03:55.768985Z","shell.execute_reply.started":"2023-05-18T19:03:55.762885Z","shell.execute_reply":"2023-05-18T19:03:55.767976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Oh, no missing values are in the dataset. We should be happy but for this case we need some missing values to apply the appropiate techniques. So let´s randomly create some `NaN`s in our dataset. ","metadata":{}},{"cell_type":"code","source":"data = original.copy()\ndata.iloc[10:11, data.columns.get_loc('Passengers')] = np.nan\ndata.iloc[25:29, data.columns.get_loc('Passengers')] = np.nan\ndata.iloc[40:45, data.columns.get_loc('Passengers')] = np.nan\ndata.iloc[70:79, data.columns.get_loc('Passengers')] = np.nan\ndata.iloc[120:125, data.columns.get_loc('Passengers')] = np.nan","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:03:57.782901Z","iopub.execute_input":"2023-05-18T19:03:57.783261Z","iopub.status.idle":"2023-05-18T19:03:57.79135Z","shell.execute_reply.started":"2023-05-18T19:03:57.783231Z","shell.execute_reply":"2023-05-18T19:03:57.789999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And check again for missing values. ","metadata":{}},{"cell_type":"code","source":"no_missing_vals = data['Passengers'].isnull().sum()\nprint(f'No of missing observations: {no_missing_vals}')\nprint(f'% of missing observations: {no_missing_vals / len(data)}')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:01.819317Z","iopub.execute_input":"2023-05-18T19:04:01.820211Z","iopub.status.idle":"2023-05-18T19:04:01.826285Z","shell.execute_reply.started":"2023-05-18T19:04:01.820161Z","shell.execute_reply":"2023-05-18T19:04:01.82547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now 24 observations are missing in our time series. Roughly 17% of our data are affected. \n\nLets plot our time series data to see the missing values. ","metadata":{}},{"cell_type":"code","source":"ax = data.plot(legend=None, figsize=(10,8))\nax.set_title('Air Passenger with missing observations')\nax.set_ylabel('Number of Passengers')\nax.set_xlabel('Date')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:03.36905Z","iopub.execute_input":"2023-05-18T19:04:03.36949Z","iopub.status.idle":"2023-05-18T19:04:03.854388Z","shell.execute_reply.started":"2023-05-18T19:04:03.369453Z","shell.execute_reply":"2023-05-18T19:04:03.85317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"## Missing value handling\n\nI will show 5 techniques for missing value handling.\n- Forward fill method (Last observation carried forward)\n- Backward fill method (Next observation carried backwards)\n- Linear interpolation\n- Spline interpolation\n- Seasonal decomposition and interpolation","metadata":{}},{"cell_type":"code","source":"ffm = data.copy()\nbfm = data.copy()\nli = data.copy()\nsi = data.copy()\nsdi = data.copy()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:07.451364Z","iopub.execute_input":"2023-05-18T19:04:07.451719Z","iopub.status.idle":"2023-05-18T19:04:07.459269Z","shell.execute_reply.started":"2023-05-18T19:04:07.451694Z","shell.execute_reply":"2023-05-18T19:04:07.457817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"### Forward fill method\n\nAs the name implies, here the missing data points are filled with the value of the last known data point. ","metadata":{}},{"cell_type":"code","source":"ffm_imputed = ffm.fillna(method='ffill')\nax = ffm_imputed.plot(linestyle=\"-\", marker=\".\", figsize=[10, 5])\nffm_imputed[ffm.isnull()].plot(ax=ax, legend=None, marker=\".\", color=\"r\")\nax.set_title('Air Passenger with missing observations')\nax.set_ylabel('Number of Passengers')\nax.set_xlabel('Date')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:09.304613Z","iopub.execute_input":"2023-05-18T19:04:09.304981Z","iopub.status.idle":"2023-05-18T19:04:09.679543Z","shell.execute_reply.started":"2023-05-18T19:04:09.304953Z","shell.execute_reply":"2023-05-18T19:04:09.678163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"### Backward fill method\n\nSame like forward fill method, but this time the missing values will be filled with the next known observation. ","metadata":{}},{"cell_type":"code","source":"bfm_imputed = bfm.fillna(method='ffill')\nax = bfm_imputed.plot(linestyle=\"-\", marker=\".\", figsize=[10, 5])\nbfm_imputed[bfm.isnull()].plot(ax=ax, legend=None, marker=\".\", color=\"r\")\nax.set_title('Air Passenger with missing observations')\nax.set_ylabel('Number of Passengers')\nax.set_xlabel('Date')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:14.242795Z","iopub.execute_input":"2023-05-18T19:04:14.243154Z","iopub.status.idle":"2023-05-18T19:04:14.74743Z","shell.execute_reply.started":"2023-05-18T19:04:14.243126Z","shell.execute_reply":"2023-05-18T19:04:14.746503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see in the above plots both methods can distort important structures of the time series (e.g. the shape of the seasonal component) depending on how large the gaps of missing data are. If these gaps are small the distortions are small, if the gaps are large then the distortions are also large. \n\nThe distortions to the time series created by data imputation can negatively impact the fitting of a model. If the proportion of missing data is small then the impact of these distortions on the fitting of a model should be less and may be tolerable depending on the use case.\n\nOne minor advantage of forward filling over backward filling is that is does not leak any data from the future to the imputed observations. \n\nIf a dataset has missing data with small gap sizes then the forward filling method would be a sufficient method to impute missing data without distorting the time series too heavily and ensuring no data leakage is occurring. Since we have a big gape size arounnd 1953, 1955 and 1959 we have to search for a better alternative. ","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"### Linear interpolation\n\nLinear interpolation in time series refers to a method of estimating missing values or filling in gaps in a time series data by assuming a linear relationship between the available data points. It assumes that the values between the known data points change linearly over time. ","metadata":{}},{"cell_type":"code","source":"li_imputed = li.interpolate(method='linear')\nax = li_imputed.plot(linestyle=\"-\", marker=\".\", figsize=[10, 5])\nli_imputed[li.isnull()].plot(ax=ax, legend=None, marker=\".\", color=\"r\")\nax.set_title('Air Passenger with missing observations')\nax.set_ylabel('Number of Passengers')\nax.set_xlabel('Date')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:17.761659Z","iopub.execute_input":"2023-05-18T19:04:17.762055Z","iopub.status.idle":"2023-05-18T19:04:18.100701Z","shell.execute_reply.started":"2023-05-18T19:04:17.762026Z","shell.execute_reply":"2023-05-18T19:04:18.099326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the above plot we can see that linear interpolation is reasonable for small gaps but also captures the trend for larger gaps. However, the seasonality is lost. ","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"### Spline interpolation\n\nSpline interpolation is used to estimate missing values or fill gaps in a time series data by fitting a smooth curve or spline to the available data points. It ais to capture the underlying pattern of the data more accurately by using a piecewise polynomial function. \n\nSpline interpolation offers several advantages over linear interpolation in time series:\n\n- It can capture more complex and non-linear patterns in the data, as cubic splines can represent a wider range of curves.\n- Spline interpolation produces a smoother curve without sharp edges, resulting in a more visually appealing representation.\n- It reduces the risk of overfitting compared to higher-degree polynomial interpolation.\n\nHowever, spline interpolation can be computationally more intensive and may require more data points to achieve accurate estimates. Additionally, the choice of spline interpolation method, such as cubic or higher-degree splines, may depend on the characteristics of the data and the desired smoothness.\n\nOverall, spline interpolation is a flexible and effective technique for estimating missing values or filling gaps in time series data, providing a more accurate representation of the underlying patterns and dynamics.","metadata":{}},{"cell_type":"code","source":"si_imputed = si.interpolate(method='spline', order=3)\nax = si_imputed.plot(linestyle=\"-\", marker=\".\", figsize=[10, 5])\nsi_imputed[si.isnull()].plot(ax=ax, legend=None, marker=\".\", color=\"r\")\nax.set_title('Air Passenger with missing observations')\nax.set_ylabel('Number of Passengers')\nax.set_xlabel('Date')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:21.134047Z","iopub.execute_input":"2023-05-18T19:04:21.13441Z","iopub.status.idle":"2023-05-18T19:04:21.466548Z","shell.execute_reply.started":"2023-05-18T19:04:21.134385Z","shell.execute_reply":"2023-05-18T19:04:21.465654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"### Seasonal decomposition and interpolation\n\nThis method involves estimating the seasonal component of a time series. This is then subtracted from the original time series to provide a de-seasoned time series. Any of the prior interpolation methods can then be used on the de-seasoned time series and the seasonal component can be added back to the de-seasoned time series.\n\nThere are many different methods to decompose a time series into seasonal and other components. We shall use STL for this notebook. n advantage of STL is that it is able to estimate a seasonal component which can change over time (e.g., if the amplitude or frequency of the seasonal component changes).\n","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.seasonal import STL","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:24.946768Z","iopub.execute_input":"2023-05-18T19:04:24.947147Z","iopub.status.idle":"2023-05-18T19:04:25.012434Z","shell.execute_reply.started":"2023-05-18T19:04:24.947119Z","shell.execute_reply":"2023-05-18T19:04:25.011418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"STL can't handle missing data. A linear interpolation is typically used to fill missing data before decomposing the time series using STL.","metadata":{}},{"cell_type":"code","source":"res = STL(sdi.interpolate(method=\"linear\"), seasonal=31).fit()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:26.5478Z","iopub.execute_input":"2023-05-18T19:04:26.548142Z","iopub.status.idle":"2023-05-18T19:04:26.55844Z","shell.execute_reply.started":"2023-05-18T19:04:26.548116Z","shell.execute_reply":"2023-05-18T19:04:26.557733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The seasonal parameter determines how much data is used to infer the seasonality at any given point. If the seasonal component is thought to be fixed throughout time then a large seasonal parameter can be set so that more data is used to determine the seasonal component. Likewise if the seasonal component is thought to change (e.g., the frequency) quickly over time the seasonal parameter can be reduced so that only recent data contributes to determining the seasonal component.\n\nThe large missing gap is linearly interpolated. This means that the algorithm sees a region of data with no seasonal component and could distort the estimation of the seasonal component. A large seasonal parameter is set to overcome this. This works because a larger portion of the data is now used to estimate the seasonal component meaning that the local distortion from the interpolation has less effect.\n\nWe now plot the decomposition to inspect that it is reasonable.","metadata":{}},{"cell_type":"code","source":"plt.rc(\"figure\", figsize=(10, 8))\nplt.rc(\"font\", size=5)\nres.plot();","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:28.706834Z","iopub.execute_input":"2023-05-18T19:04:28.707197Z","iopub.status.idle":"2023-05-18T19:04:29.993723Z","shell.execute_reply.started":"2023-05-18T19:04:28.707169Z","shell.execute_reply":"2023-05-18T19:04:29.9924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now:\n\n1. extract the seasonal component\n2. de-seasonalise the original time series\n3. perform linear interpolation on the de-seasonalised data\n4. Add the seasonal component back to the imputed de-seasonalised data","metadata":{}},{"cell_type":"code","source":"seasonal_component = res.seasonal\nseasonal_component.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:35.229787Z","iopub.execute_input":"2023-05-18T19:04:35.230142Z","iopub.status.idle":"2023-05-18T19:04:35.239128Z","shell.execute_reply.started":"2023-05-18T19:04:35.230114Z","shell.execute_reply":"2023-05-18T19:04:35.237698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdi_deseasonalised = sdi['Passengers'] - seasonal_component\nsdi_deseasonalised_imputed = sdi_deseasonalised.interpolate(method=\"linear\")\nsdi_imputed = sdi_deseasonalised_imputed + seasonal_component\nsdi_imputed = sdi_imputed.to_frame().rename(columns={0: 'Passengers'})\nax = sdi_imputed.plot(linestyle=\"-\", marker=\".\", figsize=[10, 5], legend=None)\nax = sdi_imputed[sdi.isnull()].plot(ax=ax, legend=None, marker=\".\", color=\"r\")\nax.set_title('Air Passenger with missing observations')\nax.set_ylabel('Number of Passengers')\nax.set_xlabel('Date')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:36.969074Z","iopub.execute_input":"2023-05-18T19:04:36.969407Z","iopub.status.idle":"2023-05-18T19:04:37.276924Z","shell.execute_reply.started":"2023-05-18T19:04:36.969382Z","shell.execute_reply":"2023-05-18T19:04:37.275798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Simpler seasonal decompositions methods exist in Statsmodels such as seasonal_decompose. However, the simplicity of the seasonal_decompose method has drawbacks which may or may not be relevant for your use case (e.g., naive seasonal decomposition methods may not capture seasonality which changes over time, may not return values at the start and end of a time series etc.). STL is a more advanced method that is commonly used for data imputation.","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"### Wrap up\n\nNow let´s wrap up the missing value section and plot the result of each technique in on plot to choose the best fit. ","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,15))\noriginal.plot(ax=ax, color='blue', label='Original')\nbfm_imputed.plot(ax=ax, color='black', label='FFM/BFM')\nli_imputed.plot(ax=ax, color='brown', label='Linear interpolation')\nsi_imputed.plot(ax=ax, color='red', label='Spline interpolation')\nsdi_imputed.plot(ax=ax, color='yellow', label='Seasonal decomposition and interpolation')\nplt.xlabel('Date', fontsize=15)\nplt.ylabel('Number of Passengers', fontsize=15)\nplt.title('Compare different missing values fill techniques', fontsize=15)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.legend(fontsize=15)\nax.legend(['Original', 'FFM/BFM', 'Linear interpolation', 'Spline interpolation', 'Seasonal decomposition and interpolation'], fontsize=15);\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:40.475807Z","iopub.execute_input":"2023-05-18T19:04:40.476163Z","iopub.status.idle":"2023-05-18T19:04:40.944551Z","shell.execute_reply.started":"2023-05-18T19:04:40.476135Z","shell.execute_reply":"2023-05-18T19:04:40.94367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I guess that the yellow line fits the original dataset the best. So we use seasonal decomposition and interpolation as our technique to go on. ","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"## Time series features\n\nSince we do not have any features to run the prediction, let´s extract date features from our `Date` index. ","metadata":{}},{"cell_type":"code","source":"data = sdi_imputed.copy()\ndata.reset_index(inplace=True)\ndata = data.rename(columns={'Month': 'Date'})","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:44.944355Z","iopub.execute_input":"2023-05-18T19:04:44.944772Z","iopub.status.idle":"2023-05-18T19:04:44.950947Z","shell.execute_reply.started":"2023-05-18T19:04:44.944721Z","shell.execute_reply":"2023-05-18T19:04:44.95005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Year'] = data.Date.dt.year\ndata['Month'] = data.Date.dt.month\ndata['Quarter'] = data.Date.dt.quarter\ndata['LeapYear'] = data.Date.dt.is_leap_year","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:48.458097Z","iopub.execute_input":"2023-05-18T19:04:48.45848Z","iopub.status.idle":"2023-05-18T19:04:48.4682Z","shell.execute_reply.started":"2023-05-18T19:04:48.458447Z","shell.execute_reply":"2023-05-18T19:04:48.466988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have at least a view additional columns to work with. Let´s check if we can find some relationship between the variables. ","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(28, 5))\nsns.lineplot(data=data, x='Year', y='Passengers', ax=ax)\nax.set_title('Passengers per Year')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:51.31671Z","iopub.execute_input":"2023-05-18T19:04:51.317088Z","iopub.status.idle":"2023-05-18T19:04:51.925877Z","shell.execute_reply.started":"2023-05-18T19:04:51.31706Z","shell.execute_reply":"2023-05-18T19:04:51.924957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(28, 5))\nsns.lineplot(data=data, x='Month', y='Passengers', ax=ax)\nax.set_title('Passengers per Month')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:54.583441Z","iopub.execute_input":"2023-05-18T19:04:54.583892Z","iopub.status.idle":"2023-05-18T19:04:55.197548Z","shell.execute_reply.started":"2023-05-18T19:04:54.583858Z","shell.execute_reply":"2023-05-18T19:04:55.196301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(28, 5))\nsns.lineplot(data=data, x='Quarter', y='Passengers', ax=ax)\nax.set_title('Passengers per Quarter')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:04:59.372556Z","iopub.execute_input":"2023-05-18T19:04:59.372965Z","iopub.status.idle":"2023-05-18T19:04:59.877797Z","shell.execute_reply.started":"2023-05-18T19:04:59.372932Z","shell.execute_reply":"2023-05-18T19:04:59.876861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, we have a increasing yearly trend as well as some seasonality in the `Month` and `Quarter` variables. ","metadata":{}},{"cell_type":"code","source":"sns.distplot(data['Passengers'])","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:04.364862Z","iopub.execute_input":"2023-05-18T19:05:04.365277Z","iopub.status.idle":"2023-05-18T19:05:04.71216Z","shell.execute_reply.started":"2023-05-18T19:05:04.365246Z","shell.execute_reply":"2023-05-18T19:05:04.711162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = data.corr().round(2)\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(10, 10))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": 0.7}, annot=True)\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:08.589806Z","iopub.execute_input":"2023-05-18T19:05:08.591035Z","iopub.status.idle":"2023-05-18T19:05:09.01551Z","shell.execute_reply.started":"2023-05-18T19:05:08.590984Z","shell.execute_reply":"2023-05-18T19:05:09.014099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_missing_vals = data['Passengers'].isnull().sum()\nprint(f'No of missing observations: {no_missing_vals}')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:12.365313Z","iopub.execute_input":"2023-05-18T19:05:12.365695Z","iopub.status.idle":"2023-05-18T19:05:12.372331Z","shell.execute_reply.started":"2023-05-18T19:05:12.365668Z","shell.execute_reply":"2023-05-18T19:05:12.371064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"## Modeling\n\nOkay and now let´s train a LightGBM model to predict the last 2 years. \nFirst drop our target from our feature dataframe. ","metadata":{}},{"cell_type":"code","source":"train = data.loc[data['Year'] < 1959]\ntest = data.loc[data['Year'] >= 1959]","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:14.454509Z","iopub.execute_input":"2023-05-18T19:05:14.454909Z","iopub.status.idle":"2023-05-18T19:05:14.464305Z","shell.execute_reply.started":"2023-05-18T19:05:14.454877Z","shell.execute_reply":"2023-05-18T19:05:14.463169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Train size: {len(train)}')\nprint(f'Test size: {len(test)}')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:15.684228Z","iopub.execute_input":"2023-05-18T19:05:15.684608Z","iopub.status.idle":"2023-05-18T19:05:15.689485Z","shell.execute_reply.started":"2023-05-18T19:05:15.684579Z","shell.execute_reply":"2023-05-18T19:05:15.688206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train['Passengers']\ny_test = test['Passengers']\ntest_dates = test['Date']\nX_train = train.drop(columns=['Date', 'Passengers'])\nX_test = test.drop(columns=['Date', 'Passengers'])","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:17.240933Z","iopub.execute_input":"2023-05-18T19:05:17.241377Z","iopub.status.idle":"2023-05-18T19:05:17.248952Z","shell.execute_reply.started":"2023-05-18T19:05:17.241339Z","shell.execute_reply":"2023-05-18T19:05:17.248177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:18.955921Z","iopub.execute_input":"2023-05-18T19:05:18.956374Z","iopub.status.idle":"2023-05-18T19:05:18.96222Z","shell.execute_reply.started":"2023-05-18T19:05:18.956337Z","shell.execute_reply":"2023-05-18T19:05:18.961179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'task': 'train', \n    'boosting': 'gbdt',\n    'objective': 'regression',\n    'num_leaves': 15,\n    'max_depth': 3,\n    'learning_rate': 0.1,\n    'metric': {'l2','l1'},\n    'verbose': -1\n}","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:20.827944Z","iopub.execute_input":"2023-05-18T19:05:20.828272Z","iopub.status.idle":"2023-05-18T19:05:20.836146Z","shell.execute_reply.started":"2023-05-18T19:05:20.828246Z","shell.execute_reply":"2023-05-18T19:05:20.834208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:22.829189Z","iopub.execute_input":"2023-05-18T19:05:22.829573Z","iopub.status.idle":"2023-05-18T19:05:22.834799Z","shell.execute_reply.started":"2023-05-18T19:05:22.829543Z","shell.execute_reply":"2023-05-18T19:05:22.83383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = lgb.train(params,\n                 num_boost_round=300,\n                 train_set=lgb_train,\n                 valid_sets=lgb_eval,\n                 early_stopping_rounds=20)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:25.125805Z","iopub.execute_input":"2023-05-18T19:05:25.126197Z","iopub.status.idle":"2023-05-18T19:05:25.455748Z","shell.execute_reply.started":"2023-05-18T19:05:25.126164Z","shell.execute_reply":"2023-05-18T19:05:25.454297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:53.626898Z","iopub.execute_input":"2023-05-18T19:05:53.627307Z","iopub.status.idle":"2023-05-18T19:05:53.638017Z","shell.execute_reply.started":"2023-05-18T19:05:53.627273Z","shell.execute_reply":"2023-05-18T19:05:53.63535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'MAE: {mean_absolute_error(y_test, y_preds)}')\nprint(f'MSE: {mean_squared_error(y_test, y_preds)}')\nprint(f'RMSE: {mean_squared_error(y_test, y_preds, squared=False)}')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:06:01.771811Z","iopub.execute_input":"2023-05-18T19:06:01.772225Z","iopub.status.idle":"2023-05-18T19:06:01.785639Z","shell.execute_reply.started":"2023-05-18T19:06:01.772191Z","shell.execute_reply":"2023-05-18T19:06:01.78415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The base model reaches a MAE about 74. This is semi okay, lets plot the prediction against the real values. ","metadata":{}},{"cell_type":"code","source":"test_dates = pd.DataFrame(test_dates, columns=['Date']).reset_index(drop=True)\ny_test = pd.DataFrame(y_test, columns=['Passengers']).reset_index(drop=True)\ny_preds = pd.DataFrame(y_preds, columns=['Pred_Passengers']).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:06:26.212701Z","iopub.execute_input":"2023-05-18T19:06:26.213099Z","iopub.status.idle":"2023-05-18T19:06:26.219641Z","shell.execute_reply.started":"2023-05-18T19:06:26.21307Z","shell.execute_reply":"2023-05-18T19:06:26.218612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df = pd.concat([test_dates, y_test, y_preds], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:06:28.717799Z","iopub.execute_input":"2023-05-18T19:06:28.718172Z","iopub.status.idle":"2023-05-18T19:06:28.724947Z","shell.execute_reply.started":"2023-05-18T19:06:28.718145Z","shell.execute_reply":"2023-05-18T19:06:28.723975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,15))\npred_df.plot(ax=ax, x='Date', y='Passengers')\npred_df.plot(ax=ax, x='Date', y='Pred_Passengers')\nax.set_title('Real vs. Prediction')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:06:34.469626Z","iopub.execute_input":"2023-05-18T19:06:34.469997Z","iopub.status.idle":"2023-05-18T19:06:34.956006Z","shell.execute_reply.started":"2023-05-18T19:06:34.469971Z","shell.execute_reply":"2023-05-18T19:06:34.954524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will not spend too much time in modeling. There are several approaches to generate more features, e.g. lag-features, rolling-means etc. \nI guess the model will learn better if more meaningful features were given. \n\nThe main purpose in this notebook was to provide several easy techniques to fill missing values within time series.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}